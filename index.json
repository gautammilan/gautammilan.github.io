[{"authors":null,"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n  Download my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"Milan Gautam","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://gautammilan.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Milan Gautam"],"categories":["Deep Learning"],"content":"In statistical terms, time series forecasting is the process of analyzing the time series data using statistics and modeling to make predictions and informed strategic decisions. It falls under Quantitative Forecasting. Examples of Time Series Forecasting are weather forecast over next week, forecasting the closing price of a stock each day etc. In this article we will see different types of models which can be used for this analysis and pick what is best for what situations.\nTime series data Time series data are simply measurements or events that are tracked, monitored, downsampled, and aggregated over time. This could be server metrics, application performance monitoring, network data, sensor data, events, clicks, trades in a market, and many other types of analytics data. We will be taking stock price data to perform our analysis.\nNabil bank is a bank located in Nepal, it’s been trading in NEPSE(Nepal Stock Exchange ) for the past 20 years. We can easily get this data by going to the NEPSE website. This data contains four features such as the price of the stock when the market opens on a particular date, the maximum value of the stock, the minimum value, and the value of the stock at which the market close on that day.\n   Preprocessing 1. Normalization We need to normalize between 0-1, to remove the problem which arises if the features having in different scales. But when normalizing validate and test data don’t use the validate.max() or text.max() and validate.min() or text.min() for their respective normalization use train.max and train.min for both of them. Because we can’t look at the validate or test dataset they are unknown to us. The important thing to note here is that the normalization has been done on the input feature only not on the label, the model will predict the actual value of stock.\n2. Sliding window To perform Supervised learning the dataset should have inputs and its corresponding label. Data windowing is a popular technique for converting historical data like time series to data suitable for supervised learning. It works as it sounds, we select a window for inputs and feed the model the data which has been selected into that window and the model will try to predict the label for that window. The main features of the input windows are:\n•\tThe width (number of time steps) of the input and label windows.\n•\tThe time offset between them.\n•\tWhich features are used as inputs, labels, or both.\nDepending on the task and type of model we may want to generate a variety of data windows. Here are some examples:\n A model that makes a prediction one hour into the future given six days of history, would need a window like this:     Similarly, to make a single prediction 24 days into the future, given 24 days of history, we might define a window like this:     source\nTherefore, depending upon the task and model we can generate varieties of inputs which helps to reduce the redundancy of code as by defining an data window using a class.\nModels In time series forecasting depending upon the number of steps we are going to do the prediction for the models can be classified into two types:\n1. Single step Model In single step model, model will look one step into the future. For example given all the past one month of stock data model will predict what will be the stock value tomorrow. For this task we will be using models like:\n1.1\tDense model: A single dense layer is a single layer of fully connected neural network. Here, we will be sending our Inputs of specific input width into multiple dense layer and finally the output of these dense layer will be send though a single neuron dense layer to produce a single step output. It is an regression problem where we take Open, Close, Low and High as input to predict the closing value of the stock.\n def dense_func(input_shape):  input= tf.keras.Input(shape= tf.constant(input_shape))  x= tf.keras.layers.Flatten()(input)   #Basically there are four dense layer each followed by an dropout layer  x= tf.keras.layers.Dense(units=556, activation=\u0026#39;relu\u0026#39;)(x)  x= tf.keras.layers.Dropout(0.2)(x)   x= tf.keras.layers.Dense(units=228, activation=\u0026#39;relu\u0026#39;)(x)  x= tf.keras.layers.Dropout(0.2)(x)   x= tf.keras.layers.Dense(units=128, activation=\u0026#39;relu\u0026#39;)(x)  x= tf.keras.layers.Dropout(0.2)(x)   x= tf.keras.layers.Dense(units=64, activation=\u0026#39;relu\u0026#39;)(x)  x= tf.keras.layers.Dropout(0.2)(x)   output= tf.keras.layers.Dense(units=1)(x)  model= tf.keras.Model(inputs= input,outputs= output)  return model      a. Hyperparameter tuning One of the most important hyperparameter for stock price prediction is the number of days that the model sees to make future prediction ie input_width. This hyperparameter value is calculated by training the model on different number of input width and the model which produces lowest loss it is selected.\n   We trained the model on input width [3,5,8,15,18,22,25,28,31] and among them the minimum value of MSE was obtained with the 3. So, the input width for the …","date":1643817234,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643817234,"objectID":"3fc72d77d3de20c5a20f581b609d7f6b","permalink":"https://gautammilan.github.io/post/stock-price-analysis/","publishdate":"2022-02-02T21:38:54+05:45","relpermalink":"/post/stock-price-analysis/","section":"post","summary":"In statistical terms, time series forecasting is the process of analyzing the time series data using statistics and modeling to make predictions and informed strategic decisions. It falls under Quantitative Forecasting.","tags":[],"title":"Stock Price forecasting On Nabil Bank","type":"post"},{"authors":["Milan Gautam"],"categories":["Deep Learning"],"content":"Nabil bank is a bank located in Nepal, it’s been trading in NEPSE(Nepal Stock Exchange ) for the past 20 years. We can easily get this data by going to the NEPSE website. This data contains four features such as the price of the stock when the market opens on a particular date, the maximum value of the stock, the minimum value, and the value of the stock at which the market close on that day.\nDescription There are two types of models that are widely used for time series analysis they are:\n  Single Step model= Here model will look one step into the future. For example, given all the past one month of the stock data model will predict what will be the stock value tomorrow. The dense model and LSTM model are used to evaluate the single-step model.\n  Multi-step model= In a multi-step prediction, the model needs to learn to predict a range of future values. Thus, unlike a single-step model, where only a single future point is predicted, a multi-step model predicts a sequence of the future values. The autoregressive model is used for this task.\n  Therefore in this project, we analyzed different models and evaluate which works best for our data.\nCode\nArticle\n","date":1643817234,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643817234,"objectID":"795ec18f182f4dd678f08b74e121dcbf","permalink":"https://gautammilan.github.io/project/stock-price-analysis/","publishdate":"2022-02-02T21:38:54+05:45","relpermalink":"/project/stock-price-analysis/","section":"project","summary":"Nabil bank is a bank located in Nepal, it’s been trading in NEPSE(Nepal Stock Exchange ) for the past 20 years. We can easily get this data by going to the NEPSE website.","tags":[],"title":"Stock Price forecasting On Nabil Bank","type":"project"},{"authors":["Milan Gautam"],"categories":["Deep Learning"],"content":"As most of today’s world has been digitalized, instead of writing transactions in journals people do it on their computers. In many cases, these transactions have important information about the parties involved in it, so business tries to acquire it by using many techniques. In this article, we will look into one such transaction and try to acquire embedded information inside the transaction using the deep learning model.\n   Conventional Method  As we can see the transaction contains the store number information, usually people had to go through all of these transactions to get the store number ID. But in today’s era, it’s not feasible where thousands of transaction happens every single second using various digital means.\nMapping it to machine learning problem    So basically we need to build a model which will make the transaction as an input and produce its store number. As we are emphasizing each character and determining whether it is a store number or not. Character LSTM is capable of doing this task, so the ideal choice for solving this problem is a char-LSTM model, so we will be using it.\n   Working of Bidirectional LSTM  We will approach this problem as binary classification where the position of store numbers present inside the transaction is labeled as 1 and all the other characters as 0. During inference, we will select all the characters as store numbers that have the prediction of 1. The position of the store number is not rigid and it depends upon the characters appearing on both sides of it. So it is important to look at the transaction from left to right and right to left and then select the store number. Therefore bidirectional LSTM is capable of doing that and we will be using it in this project. Similarly, the size of data that we will be working on is really small only 100 data points for train and we will use other 100 data points for validation, so we will use different training approaches to get the best out of it.\n   Dataset  Preprocessing 1. 1.\tRemoving consecutive Whitespaces We are considering whitespace as a special character, if multiple whitespaces appear in the transaction then they get tokenized using consecutive whitespace tokens, here the model will learn the necessity of adding consecutive whitespaces which is not true. So by removing the consecutive whitespaces altogether we elimate these phenomena. For example\nBefore removal: Spark 2001\nAfter removal: Spark 2001\n1.2 Removing names All the transactions have some kind of name inside them like ANN TAYLOR FACTORY #2202, MCDONALD’S F1682, etc. For some models, these names accelerate the training and for some, it works counterproductive. Depending upon the model we will be removing names from the transaction.\nBefore removal: Spark 2001\nAfter removal: 2001\n1.3 Tokenization amd Padding Dictionary is created for all the characters(a,A,c,C…), non-characters(@,#,%,…) and digits(1,2,3,4,..). Two special tokens for whitespace character and padding([PAD]) are also included in the dictionary which makes the total size of the vocabulary 87. Finally, all the characters of the transactions are tokenized using the dictionary.\nWe have considered that every transaction will have 50 characters, to make sure every transaction has the same length. If the transaction is smaller than this it is padded using padding character [PAD] and if it is larger than 50 characters then it is truncated.\n1.4 Label Creating A list of labels is created for each transaction. If the character is a store number character then it is labeled as 1 elsewhere it is labeled as 0. For transactions such as DOLRTREE 2257 00022574, where the characters forming the store number are located at two places. In such a case the store number characters which are located on the leftmost side are labeled as store number characters and the other one is ignored.\nTransaction: DOLRTREE 2257 00022574\nlabel :00000000 1111 00000000\nNote: For this example whitespace characters has not be labeled.\nModels 1.\tRegular expression model By addressing different scenario that occur on training dataset different regular expression operation has been performed on the data. The accuracy for this model is:\na.\tTraining dataset= 97%\nb.\tValidation dataset= 87%\nJust by using regular expression the accuracy of validation data is also really good which indicates there is not much difference between the training and validation set. As the possibility of overfitting is really small, we can even train the model for a large number of epochs.\n2.\tLSTM Model There are two inputs to the model one is the token and the second is the attention mask which is a Boolean matrix indicating which tokens have been padded, it is useful when training and calculating loss so that the loss of the padded token doesn’t get included on our overall loss. Similarly, as the store-number character is dependent on the characters on both sides we will use bidirectional LSTM. Bidirectional LSTM produces two outputs for every single cell, …","date":1641225234,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641225234,"objectID":"ddd9e93cdb794de46453e668fa10a15f","permalink":"https://gautammilan.github.io/post/entity-extraction/","publishdate":"2022-01-03T21:38:54+05:45","relpermalink":"/post/entity-extraction/","section":"post","summary":"As most of today’s world has been digitalized, instead of writing transactions in journals people do it on their computers. In many cases, these transactions have important information about the parties involved in it, so business tries to acquire it by using many techniques.","tags":[],"title":"Transactions entity extractor","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}   Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://gautammilan.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://gautammilan.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]